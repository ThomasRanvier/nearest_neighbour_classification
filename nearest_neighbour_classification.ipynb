{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest neighbour for handwritten digit recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I am implementing a nearest neighbour classification system in the goal to recognise handwritten digits.\n",
    "\n",
    "I will first implement an algorithm myself, and then I will use pre-existing methods to compare their efficiency.\n",
    "\n",
    "To do so I will use a part of the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing datas\n",
    "\n",
    "First I need to prepare the datas I will work on. I will use a part of the MNIST dataset : a training set of 7500 examples (instead of 60000) and a test set of 1000 (instead of 10000). \n",
    "\n",
    "The two samples contain the same number of each digit.\n",
    "\n",
    "I'm using only a part of the dataset because de nearest neighbour classification isn't a very efficient system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load the training set\n",
    "train_data = np.load('MNIST/train_data.npy')\n",
    "train_labels = np.load('MNIST/train_labels.npy')\n",
    "\n",
    "# Load the testing set\n",
    "test_data = np.load('MNIST/test_data.npy')\n",
    "test_labels = np.load('MNIST/test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set distribution:\n",
      "{0: 750, 1: 750, 2: 750, 3: 750, 4: 750, 5: 750, 6: 750, 7: 750, 8: 750, 9: 750}\n",
      "Test set distribution:\n",
      "{0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n"
     ]
    }
   ],
   "source": [
    "# Compute the number of examples of each digit\n",
    "train_digits, train_counts = np.unique(train_labels, return_counts=True)\n",
    "print(\"Training set distribution:\")\n",
    "print(dict(zip(train_digits, train_counts)))\n",
    "\n",
    "test_digits, test_counts = np.unique(test_labels, return_counts=True)\n",
    "print(\"Test set distribution:\")\n",
    "print(dict(zip(test_digits, test_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 methods that will allow me to visualize the digits and show their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : 0\n"
     ]
    }
   ],
   "source": [
    "def show_digit(x):\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "\n",
    "def vis_image(index, dataset='train'):\n",
    "    if(dataset=='train'):\n",
    "        show_digit(train_data[index])\n",
    "        label = train_labels[index]\n",
    "    else:\n",
    "        show_digit(test_data[index])\n",
    "        label = test_labels[index]\n",
    "    print(\"Label : \" + str(label))\n",
    "\n",
    "## View the first data point in the training set\n",
    "vis_image(0, \"train\")\n",
    "\n",
    "## Now view the first data point in the test set\n",
    "vis_image(0, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implemetation\n",
    "\n",
    "Now that I have a simple access to the datas and that I can visualize what I want I can begin the implementation of a brute force nearest neighbour classification.\n",
    "\n",
    "I will implement two brute force algorithms, the first using a L2 distance function and the second using a L1 distance function. The results should be slightly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Generic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function that find the nearest neighbour given a distance function\n",
    "def find_nn(x, dist_fun):\n",
    "    distances = [dist_fun(x,train_data[i]) for i in range(len(train_labels))]\n",
    "    return np.argmin(distances)\n",
    "\n",
    "# The function that returns the guessed label given a distance function\n",
    "def nn_classifier(x, dist_fun):\n",
    "    index = find_nn(x, dist_fun)\n",
    "    return train_labels[index]\n",
    "\n",
    "# The function that returns an array of all the predicted values given a distance function\n",
    "def nn(dist_fun):\n",
    "    predicted_values = np.array([nn_classifier(test_data[i], dist_fun) for i in range(len(test_labels))])\n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Euclidean distance (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The L2 distance function\n",
    "def square_l2_dist(x,y):\n",
    "    return np.sum(np.square(x-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of the L2 nearest neighbour classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of L2 nearest neighbor classifier :  0.046\n",
      "Classification time :  46.23720693588257\n"
     ]
    }
   ],
   "source": [
    "# Predict on each test data point and timer\n",
    "t_before = time.time()\n",
    "test_predictions_l2 = nn(square_l2_dist)\n",
    "t_after = time.time()\n",
    "\n",
    "# Compute the error\n",
    "err_positions = np.not_equal(test_predictions_l2, test_labels)\n",
    "error = float(np.sum(err_positions))/len(test_labels)\n",
    "\n",
    "print('Error of L2 nearest neighbor classifier : ', error)\n",
    "print('Classification time : ', t_after - t_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, the error rate is 4.6% using an euclidean distance, it's a pretty good result as this classification method is extremely simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Taxicab distance (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The L1 distance function\n",
    "def square_l1_dist(x,y):\n",
    "    return np.sum(np.abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of L1 nearest neighbor classifier :  0.056\n",
      "Classification time :  42.40626907348633\n"
     ]
    }
   ],
   "source": [
    "# Predict on each test data point and timer\n",
    "t_before = time.time()\n",
    "test_predictions_l1 = nn(square_l1_dist)\n",
    "t_after = time.time()\n",
    "\n",
    "# Compute the error\n",
    "err_positions = np.not_equal(test_predictions_l1, test_labels)\n",
    "error = float(np.sum(err_positions))/len(test_labels)\n",
    "\n",
    "print('Error of L1 nearest neighbor classifier : ', error)\n",
    "print('Classification time : ', t_after - t_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rate is 5.6% using a taxicab distance, it's slightly less precise than with a L2 distance but the classification time is little bit lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparaison with better functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. BallTree method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build data structure :  0.4631025791168213\n",
      "Time to classify test set :  8.949438095092773\n",
      "Ball tree produces same predictions as L2 ?  True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Build nearest neighbor structure on training data\n",
    "t_before = time.time()\n",
    "ball_tree = BallTree(train_data)\n",
    "t_after = time.time()\n",
    "\n",
    "print(\"Time to build data structure : \", t_after - t_before)\n",
    "\n",
    "# Get nearest neighbor predictions on testing data\n",
    "t_before = time.time()\n",
    "test_neighbors = np.squeeze(ball_tree.query(test_data, k=1, return_distance=False))\n",
    "ball_tree_predictions = train_labels[test_neighbors]\n",
    "t_after = time.time()\n",
    "\n",
    "print(\"Time to classify test set : \", t_after - t_before)\n",
    "\n",
    "print(\"Ball tree produces same predictions as L2 ? \", np.array_equal(test_predictions_l2,ball_tree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build data structure :  0.4234342575073242\n",
      "Time to classify test set :  10.94090747833252\n",
      "KD tree produces same predictions as L2 ?  True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "# Build nearest neighbor structure on training data\n",
    "t_before = time.time()\n",
    "kd_tree = KDTree(train_data)\n",
    "t_after = time.time()\n",
    "\n",
    "print(\"Time to build data structure : \", t_after - t_before)\n",
    "\n",
    "# Get nearest neighbor predictions on testing data\n",
    "t_before = time.time()\n",
    "test_neighbors = np.squeeze(kd_tree.query(test_data, k=1, return_distance=False))\n",
    "kd_tree_predictions = train_labels[test_neighbors]\n",
    "t_after = time.time()\n",
    "\n",
    "print(\"Time to classify test set : \", t_after - t_before)\n",
    "\n",
    "print(\"KD tree produces same predictions as L2 ? \", np.array_equal(test_predictions_l2,kd_tree_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above those two methods are way more efficient than a brute force algorithm, but the results are\n",
    "the same because those two methods are using a L2 function too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
